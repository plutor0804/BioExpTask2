import os, time, numpy as np, torch, joblib, pyautogui
from pynput.keyboard import Controller, Key
from scipy.signal import butter, filtfilt

# ========== åƒæ•¸ ==========
# ---- EEG ç‰¹å¾µ ----
VEC_DIM   = 248          # 496 (=10 s) æˆ– 251 (=5 s)
META_DIM  = 20           # 12+5+3
NUM_CLASS = 4

# ---- æ™‚é–“ç‰‡é•·åº¦ ----
SEG_LEN   = 2500 #if VEC_DIM == 496 else 2500   # 5000 é»ž=10 sï¼›2500 é»ž=5 s
CENTER_EXTRACT = True                          # å–æ­£ä¸­å¤®ä¸€æ®µ

# ---- æª”æ¡ˆ & æ¨¡åž‹ ----
MODEL_PATH  = "../models/5s model/10.pt"
SCALER_PATH = "../models/5s model/10.pkl"
EEG_FILE    = "../data/data_val/stress/1.txt"           # ç›£è½çš„ txt æª”

# ---- éŠæˆ²åº§æ¨™ ----
CLICK_MAZE_X, CLICK_MAZE_Y      = 357,  511
CLICK_TERM_X, CLICK_TERM_Y      = 1734, 1005

# ========== UI å·¥å…· ==========
def focus_maze():   pyautogui.click(CLICK_MAZE_X, CLICK_MAZE_Y)
def focus_term():   pyautogui.click(CLICK_TERM_X, CLICK_TERM_Y)

# ========== æ¨¡åž‹ ==========
class HybridCNN(torch.nn.Module):
    def __init__(self, vec_dim, meta_dim, num_cls):
        super().__init__()
        self.vec_dim = vec_dim
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv1d(1, 32, 5, padding=2), torch.nn.BatchNorm1d(32), torch.nn.ReLU(),
            torch.nn.MaxPool1d(2),
            torch.nn.Conv1d(32, 64, 5, padding=2), torch.nn.BatchNorm1d(64), torch.nn.ReLU(),
            torch.nn.AdaptiveAvgPool1d(1), torch.nn.Flatten()
        )
        self.mlp = torch.nn.Sequential(
            torch.nn.Linear(meta_dim, 64), torch.nn.ReLU(), torch.nn.Dropout(0.3)
        )
        self.classifier = torch.nn.Sequential(
            torch.nn.Linear(64+64, 64), torch.nn.ReLU(), torch.nn.Dropout(0.3),
            torch.nn.Linear(64, num_cls)
        )



    def forward(self, x):
        v   = x[:, :self.vec_dim].unsqueeze(1)
        met = x[:, self.vec_dim:]
        return self.classifier(torch.cat([self.cnn(v), self.mlp(met)], 1))

# ========== ç‰¹å¾µ ==========
def extract_features(vec):
    v, vs = vec, vec + 1e-8
    f = [np.mean(v), np.std(v), np.sqrt(np.mean(v**2)), np.min(v), np.max(v),
         np.percentile(v,25), np.median(v), np.percentile(v,75),
         np.mean((v-np.mean(v))**3)/(np.std(v)**3+1e-8),
         np.mean((v-np.mean(v))**4)/(np.std(v)**4+1e-8),
         np.sum(v**2),
         -np.sum((vs/vs.sum())*np.log(vs/vs.sum()))]
    return np.array(f)

def extract_band_power(vec, freqs):
    bands = {"delta":(0.5,4),"theta":(4,8),"alpha":(8,13),"beta":(13,30),"gamma":(30,50)}
    return np.array([np.mean(vec[(freqs>=lo)&(freqs<hi)]) for lo,hi in bands.values()])

def compute_ratios(b):
    Î¸, Î±, Î² = b[1], b[2], b[3]
    return np.array([Î¸/(Î±+1e-8), Î±/(Î²+1e-8), Î²/(Î¸+1e-8)])

# ---- æ¿¾æ³¢å™¨ä¸€æ¬¡å»ºç«‹ ----
b_bp, a_bp = butter(4, [0.5,50], btype='bandpass', fs=500)

def load_single_txt(txt_path):

    with open(txt_path, encoding='utf-8') as f:
        raw = np.loadtxt(f, skiprows=1)
    if len(raw) < SEG_LEN:
        raise ValueError("æª”æ¡ˆé»žæ•¸ä¸è¶³")

    # ---- ä¸­å¤® SEG_LEN ----
    s = len(raw)//2 - SEG_LEN//2
    seg = raw[s:s+SEG_LEN]

    # ---- æ¿¾æ³¢ & FFT ----
    filt  = filtfilt(b_bp, a_bp, seg)
    power = np.abs(np.fft.rfft(filt, n=SEG_LEN))**2
    logp  = np.log1p(power)

    freqs = np.fft.rfftfreq(SEG_LEN, d=1/500)
    idx   = (freqs >= 0.5) & (freqs <= 50)

    vec    = logp[idx]          # 248 bin
    f_used = freqs[idx]         # 248 freq


    # ---- ç‰¹å¾µ ----
    stat  = extract_features(vec)
    band  = extract_band_power(vec, f_used)   # å…©è€…é•·åº¦ç›¸åŒ
    ratio = compute_ratios(band)
    return np.concatenate([vec, stat, band, ratio])

# ========== è¼‰å…¥æ¨¡åž‹ ==========
model  = HybridCNN(VEC_DIM, META_DIM, NUM_CLASS)
model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
model.eval()
scaler = joblib.load(SCALER_PATH)

label_map = ["relax", "concentrating", "stress", "memory"]
dir_map   = {"relax":Key.right, "concentrating":Key.right, "stress":Key.left, "memory":Key.down}
kbd = Controller()

N_EEG = N_manual = 0

def predict_and_press(p):
    global N_EEG, N_manual
    x = scaler.transform(load_single_txt(p).reshape(1,-1))
    with torch.no_grad():
        pred = model(torch.tensor(x, dtype=torch.float32))
        label = label_map[pred.argmax(1).item()]
    print("âœ… é æ¸¬ï¼š", label)

    choice = input("â–¶ Enter=æŽ¡ç”¨ï½œw/a/s/d=").strip().lower()
    if choice in ['w','a','s','d']:
        key = {'w':Key.up,'s':Key.down,'a':Key.left,'d':Key.right}[choice]
        is_eeg=False
    else:
        key = dir_map[label]; is_eeg=True

    try: steps=int(input("ðŸ§­ æ­¥æ•¸ï¼š"))
    except: steps=1
    if steps<=0: return

    focus_maze()
    for _ in range(steps):
        kbd.press(key); time.sleep(0.07); kbd.release(key)
    focus_term()

    if is_eeg: N_EEG += steps
    else:      N_manual += steps
    print(f"ðŸ“Š EEG:{N_EEG} | æ‰‹å‹•:{N_manual}")

# ========== ç›£è½è¿´åœˆ ==========
def main():
    print("ðŸ§  å³æ™‚é æ¸¬ä¸­â€¦ (æª”æ¡ˆè®Šå‹•è§¸ç™¼)"); last_m = None
    while True:
        if os.path.exists(EEG_FILE):
            m = os.path.getmtime(EEG_FILE)
            if m != last_m:
                last_m = m
                try:    predict_and_press(EEG_FILE)
                except Exception as e: print("âš ï¸", e)
        else:
            print("âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ", EEG_FILE)
        time.sleep(0.5)

if __name__ == "__main__":
    main()
