import os
import time
import torch
import numpy as np
import joblib
import pyautogui
from pynput.keyboard import Controller, Key

# === éŠæˆ²èˆ‡çµ‚ç«¯æ©Ÿä½ç½®åº§æ¨™ï¼ˆéœ€æ‰‹å‹•é‡æ¸¬ï¼‰ ===
CLICK_MAZE_X = 357
CLICK_MAZE_Y = 511
CLICK_TERMINAL_X = 1734
CLICK_TERMINAL_Y = 1005

def focus_maze_window():
    try:
        pyautogui.click(CLICK_MAZE_X, CLICK_MAZE_Y)
        print("åˆ‡æ›è‡³è¿·å®®è¦–çª—")
    except Exception as e:
        print(f"âŒ åˆ‡æ›å¤±æ•—ï¼š{e}")

def focus_terminal_window():
    try:
        pyautogui.click(CLICK_TERMINAL_X, CLICK_TERMINAL_Y)
        print("åˆ‡æ›è‡³çµ‚ç«¯æ©Ÿè¦–çª—")
    except Exception as e:
        print(f"âŒ åˆ‡æ›å¤±æ•—ï¼š{e}")

# === CNN + å°å‹ MLP æ¨¡å‹æ¶æ§‹ ===
class HybridCNN(torch.nn.Module):
    def __init__(self, vec_dim, meta_dim, num_classes):
        super().__init__()
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv1d(1, 32, kernel_size=5, padding=2),
            torch.nn.BatchNorm1d(32),
            torch.nn.ReLU(),
            torch.nn.MaxPool1d(2),
            torch.nn.Conv1d(32, 64, kernel_size=5, padding=2),
            torch.nn.BatchNorm1d(64),
            torch.nn.ReLU(),
            torch.nn.AdaptiveAvgPool1d(1),
            torch.nn.Flatten()
        )
        self.mlp = torch.nn.Sequential(
            torch.nn.Linear(meta_dim, 64),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3)
        )
        self.classifier = torch.nn.Sequential(
            torch.nn.Linear(64 + 64, 64),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(64, num_classes)
        )

    def forward(self, x):
        vec = x[:, :496].unsqueeze(1)
        meta = x[:, 496:]
        cnn_out = self.cnn(vec)
        mlp_out = self.mlp(meta)
        return self.classifier(torch.cat([cnn_out, mlp_out], dim=1))

# === ç‰¹å¾µè™•ç†å‡½æ•¸ ===
def compute_band_ratios(band_feat):
    theta, alpha, beta = band_feat[1], band_feat[2], band_feat[3]
    return np.array([
        theta / (alpha + 1e-8),
        alpha / (beta + 1e-8),
        beta / (theta + 1e-8)
    ])

def extract_band_power(vec, freqs):
    bands = {
        "delta": (0.5, 4),
        "theta": (4, 8),
        "alpha": (8, 13),
        "beta": (13, 30),
        "gamma": (30, 50)
    }
    powers = []
    for (low, high) in bands.values():
        idx = np.where((freqs >= low) & (freqs < high))
        powers.append(np.mean(vec[idx]))
    return np.array(powers)


def extract_features(vec):
    vec_safe = vec + 1e-8
    return np.array([
        np.mean(vec),
        np.std(vec),
        np.sqrt(np.mean(vec ** 2)),
        np.min(vec),
        np.max(vec),
        np.percentile(vec, 25),
        np.median(vec),
        np.percentile(vec, 75),
        np.mean((vec - np.mean(vec))**3) / (np.std(vec)**3 + 1e-8),
        np.mean((vec - np.mean(vec))**4) / (np.std(vec)**4 + 1e-8),
        np.sum(vec**2),
        -np.sum((vec_safe/np.sum(vec_safe)) * np.log(vec_safe/np.sum(vec_safe)))
    ])

def load_single_txt_with_features(txt_path):
    fs = 500
    raw = np.loadtxt(txt_path)
    N = len(raw)
    if N < 10_000:
        raise ValueError(f"æª”æ¡ˆåªæœ‰ {N} é»ï¼Œå°‘æ–¼ 10 000")

    start = (N - 5000) // 2      # äº¦å¯å¯«æˆ N//2 - 5000
    raw = raw[start : start + 5000]   # å–æ­£ä¸­é–“ 10 ç§’è³‡æ–™ (500 Hz)


    # === FFT â†’ log(1+power) ===
    n_fft      = (len(raw) - 1) * 2              # 19 998
    fft_result = np.fft.rfft(raw, n=n_fft)
    power      = np.abs(fft_result) ** 2
    log_power  = np.log1p(power)

    # 0.5â€“50 Hz ç¯„åœ
    freqs = np.fft.rfftfreq(n_fft, d=1/fs)
    idx   = (freqs >= 0.5) & (freqs <= 50)
    log_power = log_power[idx]
    freqs     = freqs[idx]

    # **ä¿ç•™å‰ 496 ç¶­**â”€â”€èˆ‡è¨“ç·´ä¸€è‡´
    if len(log_power) < 496:
        raise ValueError(f"é »åŸŸè³‡æ–™åªæœ‰ {len(log_power)} é»ï¼Œå°‘æ–¼ 496")
    log_power = log_power[:496]
    freqs     = freqs[:496]

    # 20 ç¶­è¼”åŠ©ç‰¹å¾µ
    stat_feat  = extract_features(log_power)
    band_feat  = extract_band_power(log_power, freqs)
    ratio_feat = compute_band_ratios(band_feat)

    # 496 + 20 = 516 ç¶­
    return np.concatenate([log_power, stat_feat, band_feat, ratio_feat])

# === è¼‰å…¥æ¨¡å‹èˆ‡ Scaler ===
VEC_DIM = 496           # log-power éƒ¨åˆ†
META_DIM = 20           # çµ±è¨ˆ+band+ratio
NUM_CLASSES = 4

model = HybridCNN(vec_dim=VEC_DIM, meta_dim=META_DIM, num_classes=NUM_CLASSES)
model.load_state_dict(torch.load("../models/model6/best_hybrid_model.pt", map_location=torch.device('cpu')))
model.eval()
scaler = joblib.load("../models/model6/best_scaler.pkl")

label_map = ["relax", "concentrating", "stress", "memory"]
direction_map = {
    "relax": Key.right,
    "concentrating": Key.right,
    "memory": Key.down,
    "stress": Key.left,
}
keyboard = Controller()

# === å–®ç­†é æ¸¬ä¸¦æ¨¡æ“¬æŒ‰éµ ===

N_EEG = 0
N_manual = 0

def predict_and_press(path):
    global N_EEG, N_manual

    try:
        x_raw    = load_single_txt_with_features(path)
        x_scaled = scaler.transform(x_raw.reshape(1, -1))
        x_tensor = torch.tensor(x_scaled, dtype=torch.float32)

        with torch.no_grad():
            output = model(x_tensor)
            pred_idx = torch.argmax(output, dim=1).item()
            signal   = label_map[pred_idx]

        print(f"âœ… é æ¸¬æ–¹å‘ï¼š{signal}")

        # ---- æ±ºå®šä½¿ç”¨ EEG é‚„æ˜¯æ‰‹å‹• ----
        choice = input("â–¶ ç›´æ¥æ¡ç”¨é æ¸¬(Enter) æˆ–è¼¸å…¥ w/a/s/d ä¿®æ­£æ–¹å‘ï¼Ÿ ").strip().lower()

        # â‡¢ è‹¥ choice ç‚ºç©ºå­—ä¸² â†’ æ¡ç”¨é æ¸¬æ–¹å‘
        if choice == "":
            direction_key = direction_map[signal]
            is_eeg_move = True
        else:
            # æ‰‹å‹•æŒ‡å®š w/a/s/d â†’ å°æ‡‰å››æ–¹å‘
            manual_dir = {
                "w": Key.up,
                "s": Key.down,
                "a": Key.left,
                "d": Key.right
            }.get(choice)

            if manual_dir is None:
                print("âš ï¸ ç„¡æ•ˆè¼¸å…¥ï¼Œè·³éæœ¬æ¬¡ç§»å‹•")
                return
            direction_key = manual_dir
            is_eeg_move   = False

        # ---- è¼¸å…¥æ­¥æ•¸ ----
        try:
            steps = int(input("ğŸ§­ è«‹è¼¸å…¥æ­¥æ•¸(æ•´æ•¸)ï¼š"))
        except ValueError:
            print("âš ï¸ è¼¸å…¥ç„¡æ•ˆï¼Œé è¨­ 1 æ­¥")
            steps = 1
        if steps <= 0:
            print("âš ï¸ æ­¥æ•¸éœ€ > 0ï¼Œå–æ¶ˆæœ¬æ¬¡")
            return

        # ---- åŸ·è¡Œéµç›¤è¼¸å…¥ ----
        focus_maze_window()
        for _ in range(steps):
            keyboard.press(direction_key)
            time.sleep(0.07)
            keyboard.release(direction_key)
        focus_terminal_window()

        # ---- æ›´æ–°è¨ˆæ•¸ ----
        if is_eeg_move:
            N_EEG += steps
        else:
            N_manual += steps

        # ---- é¡¯ç¤ºçµ±è¨ˆ ----
        print(f"ğŸ“Š N_EEG = {N_EEG}, N_manual = {N_manual}")

    except Exception as e:
        print(f"âš ï¸ é æ¸¬/æ“ä½œå¤±æ•—ï¼š{e}")
# === ä¸»åŸ·è¡Œè¿´åœˆ ===

def main():
    print("ğŸ§  é€²å…¥å³æ™‚é æ¸¬æ¨¡å¼ï¼Œ0.5 ç§’è¼ªè©¢ä¸€æ¬¡ â€¦")
    path = "../data/bci_dataset_113-2/S01/6.txt"
    last_mtime = None           # ä¸Šæ¬¡çœ‹åˆ°çš„æª”æ¡ˆä¿®æ”¹æ™‚é–“

    while True:
        if os.path.exists(path):
            try:
                mtime = os.path.getmtime(path)   # å–å¾—æœ€å¾Œä¿®æ”¹æ™‚é–“ (float, ç§’)
            except OSError as e:
                # æª”æ¡ˆæ­£è¢«å¯«å…¥è€Œæš«æ™‚é–ä½ â†’ ç¨å¾Œå†è©¦
                print(f"âš ï¸ è®€å– {path} å¤±æ•—ï¼š{e}")
                time.sleep(0.5)
                continue

            # åªæœ‰æ™‚é–“æˆ³ä¸åŒæ‰é‡æ–°æ¨è«–
            if mtime != last_mtime:
                last_mtime = mtime
                predict_and_press(path)

        else:
            print("âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œç­‰å¾…ä¸­â€¦")

        time.sleep(0.5)         # æ¯åŠç§’è¼ªè©¢ä¸€æ¬¡

if __name__ == "__main__":
    main()
