import os
import time
import torch
import numpy as np
import joblib
import pyautogui
import threading
from pynput.keyboard import Controller, Key, Listener

# === éŠæˆ²è¦–çª—ä½ç½®ï¼ˆéœ€æ‰‹å‹•æ¸¬é‡ï¼‰===
CLICK_MAZE_X = 581
CLICK_MAZE_Y = 30
CLICK_TERMINAL_X = 1438
CLICK_TERMINAL_Y = 977

N_manual = 0
N_EEG = 0

def focus_maze_window():
    try:
        pyautogui.click(CLICK_MAZE_X, CLICK_MAZE_Y)
        print("ðŸ”„ åˆ‡æ›åˆ°è¿·å®®éŠæˆ²è¦–çª—")
    except Exception as e:
        print(f"âŒ è¿·å®®è¦–çª—åˆ‡æ›å¤±æ•—ï¼š{e}")

def focus_terminal_window():
    try:
        pyautogui.click(CLICK_TERMINAL_X, CLICK_TERMINAL_Y)
        print("ðŸ”„ åˆ‡æ›å›ž Terminal è¦–çª—")
    except Exception as e:
        print(f"âŒ Terminal åˆ‡æ›å¤±æ•—ï¼š{e}")

# === æ¨¡åž‹æž¶æ§‹ ===
class EEGMLP(torch.nn.Module):
    def __init__(self, input_dim, num_classes):
        super().__init__()
        self.model = torch.nn.Sequential(
            torch.nn.Linear(input_dim, 128),
            torch.nn.BatchNorm1d(128),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.4),
            torch.nn.Linear(128, 64),
            torch.nn.BatchNorm1d(64),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.4),
            torch.nn.Linear(64, num_classes)
        )
    def forward(self, x):
        return self.model(x)

# === ç‰¹å¾µæ“·å– ===
def extract_band_power(vec, freqs):
    bands = {
        "delta": (0.5, 4),
        "theta": (4, 8),
        "alpha": (8, 13),
        "low-beta": (13, 20),
        "high-beta": (20,30),
        "gamma": (30, 50)
    }
    powers = []
    for (low, high) in bands.values():
        idx = np.where((freqs >= low) & (freqs < high))
        powers.append(np.mean(vec[idx]))
    return np.array(powers)

def extract_features(vec):
    vec_safe = vec + 1e-8
    return np.array([
        np.mean(vec),
        np.std(vec),
        np.sqrt(np.mean(vec ** 2)),
        np.min(vec),
        np.max(vec),
        np.percentile(vec, 25),
        np.median(vec),
        np.percentile(vec, 75),
        np.mean((vec - np.mean(vec))**3) / (np.std(vec)**3 + 1e-8),
        np.mean((vec - np.mean(vec))**4) / (np.std(vec)**4 + 1e-8),
        np.sum(vec**2),
        -np.sum((vec_safe/np.sum(vec_safe)) * np.log(vec_safe/np.sum(vec_safe)))
    ])

def load_single_txt_with_features(txt_path):
    vec = np.loadtxt(txt_path)
    vec = vec[:10000]
    fft_result = np.fft.rfft(vec, n=10000)
    power = np.abs(fft_result) ** 2
    log_power = np.log1p(power)
    freqs = np.fft.rfftfreq(10000, d=1/500)
    stat_feat = extract_features(log_power)
    band_feat = extract_band_power(log_power, freqs)
    return np.concatenate([log_power, stat_feat, band_feat])

# === è¼‰å…¥æ¨¡åž‹èˆ‡ scaler ===
model = EEGMLP(5019, 4)
model.load_state_dict(torch.load("../models/subject9_best_model_1.pt", weights_only=True))
model.eval()
scaler = joblib.load("../models/scaler_subject9.pkl")

label_map = ["relax", "concentrating", "stress", "memory"]
signal_to_key = {
    "relax": Key.up,
    "concentrating": Key.down,
    "memory": Key.left,
    "stress": Key.right
}
keyboard = Controller()

# === è…¦æ³¢é æ¸¬æŽ§åˆ¶ ===
def predict_and_press(path="live_data.txt"):
    global N_EEG
    try:
        x_raw = load_single_txt_with_features(path)
        x_scaled = scaler.transform(x_raw.reshape(1, -1))
        x_tensor = torch.tensor(x_scaled, dtype=torch.float32)

        with torch.no_grad():
            output = model(x_tensor)
            pred_idx = torch.argmax(output, dim=1).item()
            signal = label_map[pred_idx]

        print(f"âœ… è…¦æ³¢é æ¸¬çµæžœï¼š{signal}")

        if signal in signal_to_key:
            try:
                steps = int(input("ðŸ§­ è«‹è¼¸å…¥æ­¥æ•¸ï¼ˆæ•´æ•¸ï¼‰ï¼š"))
            except ValueError:
                print("âš ï¸ é è¨­æ­¥æ•¸ç‚º 1")    
                steps = 1

            focus_maze_window()
            for _ in range(steps):
                keyboard.press(signal_to_key[signal])
                time.sleep(0.07)
                keyboard.release(signal_to_key[signal])
            focus_terminal_window()

            N_EEG += steps
            print(f"ðŸ“Š EEG æŽ§åˆ¶ç¸½æ­¥æ•¸ï¼š{N_EEG}")

    except Exception as e:
        print(f"âš ï¸ EEG é æ¸¬éŒ¯èª¤ï¼š{e}")

# === æ‰‹å‹•æŽ§åˆ¶ç›£è½å™¨ ===
manual_key_map = {
    'i': "relax",        # â†‘
    'k': "concentrating",# â†“
    'l': "stress",       # â†’
    'j': "memory"        # â†
}

def on_press(key):
    global N_manual
    try:
        k = key.char.lower()
        if k in manual_key_map:
            signal = manual_key_map[k]
            if signal in signal_to_key:
                try:
                    steps = int(input(f"ðŸ§­ [æ‰‹å‹•] è«‹è¼¸å…¥ {signal} çš„æ­¥æ•¸ï¼ˆæ•´æ•¸ï¼‰ï¼š"))
                except ValueError:
                    print("âš ï¸ ç„¡æ•ˆè¼¸å…¥ï¼Œé è¨­æ­¥æ•¸ç‚º 1")
                    steps = 1

                focus_maze_window()
                for _ in range(steps):
                    keyboard.press(signal_to_key[signal])
                    time.sleep(0.07)
                    keyboard.release(signal_to_key[signal])
                focus_terminal_window()

                N_manual += steps
                print(f"ðŸ•¹ï¸ æ‰‹å‹•æŽ§åˆ¶æ–¹å‘ï¼š{signal}ï¼Œç¸½æ‰‹å‹•æ­¥æ•¸ï¼š{N_manual}")
    except AttributeError:
        pass  # å¿½ç•¥ç‰¹æ®Šéµ


def start_manual_listener():
    listener = Listener(on_press=on_press)
    listener.start()

# === ä¸»è¿´åœˆ ===
def main():
    print("ðŸ§  EEG å³æ™‚é æ¸¬å•Ÿå‹•ï¼Œæ¯ 20 ç§’æŽƒæä¸€æ¬¡è³‡æ–™")
    print("ðŸŽ® æ‰‹å‹•æŽ§åˆ¶ï¼ši=â†‘ j=â† k=â†“ l=â†’")
    start_manual_listener()

    while True:
        if os.path.exists("../data/bci_dataset_113-2/S01/1.txt"):
            predict_and_press("../data/bci_dataset_113-2/S01/1.txt")
        else:
            print("âš ï¸ æ‰¾ä¸åˆ° EEG æª”æ¡ˆï¼Œç­‰å¾…ä¸­...")
        time.sleep(20)

if __name__ == "__main__":
    main()
